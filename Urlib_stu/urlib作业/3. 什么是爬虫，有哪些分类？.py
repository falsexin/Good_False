#
# @Time    : 2019/1/7 17:28
# @Author  : Mat
# @欣      ：Very Cool
# @File    : 3. 什么是爬虫，有哪些分类？.py
# @Software: PyCharm
#  ......................我佛慈悲......................
#                        _oo0oo_
#                       o8888888o
#                       88" . "88
#                       (| -_- |)
#                       0\  =  /0
#                     ___/`---'\___
#                   .' \\|     |// '.
#                  / \\|||  :  |||// \
#                 / _||||| -卍-|||||- \
#                |   | \\\  -  /// |   |
#                | \_|  ''\---/''  |_/ |
#                \  .-\__  '-'  ___/-. /
#              ___'. .'  /--.--\  `. .'___
#           ."" '<  `.___\_<|>_/___.' >' "".
#          | | :  `- \`.;`\ _ /`;.`/ - ` : | |
#          \  \ `_.   \_ __\ /__ _/   .-` /  /
#      =====`-.____`.___ \_____/___.-`___.-'=====
#                        `=---='
#
# ..................佛祖开光 ,永无BUG...................
# ..................佛祖保佑，永不加班...................


# 爬虫是一种按照一定的规则 自动地抓取互联网信息的程序或者脚本
# 分类
#
# 通用爬虫（General Purpose Web Crawler）
# 搜索引擎 百度 谷歌等 的重要组成部分
# 主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。
#
# 聚焦爬虫（Focused Web Crawler）
# 是"面向特定主题需求"的一种网络爬虫程序，它与通用搜索引擎爬虫的区别在于： 聚焦
# 爬虫在实施网页抓取时会对内容进行处理筛选，尽量保证只抓取与需求相关的网页信息。
#
# 增量式爬虫（Incremental Web Crawler）
# 是指在具有一定量规模的网络页面集合的基础上，采用更新数据的方式选取已有集合中的过
# 时网页进行抓取，以保证所抓取到的数据与真实网络数据足够接近。进行增量式抓取的前提
# 是，系统已经抓取了足够数量的网络页面，并具有这些页面被抓取的时间信息。
#
#
# 深层爬虫（Deep Web Crawler）
# 针对起始 url 地址进行数据采集，在响应数据中进行数据筛选得到需要进行数据采集的下一
# 波 url 地址，并将 url 地址添加到数据采集队列中进行二次爬取..以此类推，一致到所有页面
# 的数据全部采集完成即可完成深度数据采集，这里的深度指的就是 url 地址的检索深度


